## HashMap 拓容因子为什么是0.75

### HashTable 初始容量是11,扩容 方式为2N+1;

### HashMap 初始容量是16,扩容方式为2N;

### 原因总结

- 提高`空间利用率`和`减少查询成本`的折中，0.75的话碰撞最小。
---

### HashMap有两个参数影响其性能：初始容量和加载因子

- **容量是哈希表中桶的数量**，初始容量只是哈希表在创建时的容量。
  
- 加载因子是哈希表在其容量自动扩容之前可以达到多满的一种度量。当哈希表中的条目数超出了加载因子与当前容量的乘积时,则要对该哈希表进行扩容、rehash操作（即重建内部数据结构），扩容后的哈希表将具有两倍的原容量。

#### 加载因子的内涵

- 加载因子需要在时间和空间成本上寻求一种折衷;

- 加载因子过高，例如为1，虽然减少了空间开销，提高了空间利用率，但同时也增加了查询时间成本;

- 加载因子过低，例如0.5，虽然可以减少查询时间成本，但是空间利用率很低，同时提高了rehash操作的次数;

- 在设置初始容量时应该考虑到映射中所需的条目数及其加载因子，以便最大限度地减少rehash操作次数，所以，一般在使用HashMap时建议根据预估值设置初始容量，减少扩容操作;

- 选择0.75作为默认的加载因子，**完全是时间和空间成本上寻求的一种折衷选择**

----------

#### HashMap源码中的加载因子
````
static final float DEFAULT_LOAD_FACTOR = 0.75f; 
```` 
- 跟数据结构要么查询快要么插入快一个道理，hashmap就是一个插入慢、查询快的数据结构。

- 加载因子是表示Hash表中元素的填满的程度。 加载因子越大,填满的元素越多,空间利用率越高，但冲突的机会加大了。 反之,加载因子越小,填满的元素越少,冲突的机会减小,但空间浪费多了。

- 冲突的机会越大,则查找的成本越高。反之,查找的成本越小。 因此,必须在 `"冲突的机会"`与`"空间利用率"`之间寻找一种平衡与折衷。

#### 哈希冲突主要与两个因素有关:

- **填装因子**，填装因子是指哈希表中已存入的数据元素个数与哈希地址空间的大小的比值，a=n/m ; a越小，冲突的可能性就越小，相反则冲突可能性较大；但是a越小空间利用率也就越小，a越大，空间利用率越高，为了兼顾哈希冲突和存储空间利用率，通常将a控制在`0.6-0.9`之间，而.net中的HashTable则直接将a的最大值定义为0.72 （虽然微软官方MSDN中声明HashTable默认填装因子为1.0，但实际上都是0.72的倍数），
  
- **与所用的哈希函数**有关，如果哈希函数得当，就可以使哈希地址尽可能的均匀分布在哈希地址空间上，从而减少冲突的产生，但一个良好的哈希函数的得来很大程度上取决于大量的实践，不过幸好前人已经总结实践了很多高效的哈希函数，可以参考大神Lucifer文章,数据结构：HashTable
  [link](http://www.cnblogs.com/lucifer1982/archive/2008/06/18/1224319.html)
  
----

### 处理冲突的几种方法:

#### 第一种:开放寻址法

Hi=(H(key) + di) MOD m i=1,2,...k(k<=m-1)其中H(key)为哈希函数；m为哈希表表长；di为增量序列。

开放定址法根据步长不同可以分为３种：

- 线性探查法(Linear Probing)：di=1,2,3,...,m-1
简单地说就是以当前冲突位置为起点，步长为１循环查找，直到找到一个空的位置就把元素插进去，循环完了都找不到说明容器满了。就像你去一条街上的店里吃饭，问了第一家被告知满座，然后挨着一家家去问是否有位置一样。

- 线性补偿探测法：di=Ｑ　下一个位置满足 Hi=(H(key) + Ｑ) mod m i=1,2,...k(k<=m-1) ，要求 Q 与 m 是互质的，以便能探测到哈希表中的所有单元。
继续用上面的例子，现在你不是挨着一家家去问了，拿出计算器算了一下，然后隔Ｑ家问一次有没有位置。

- 伪随机探测再散列：di=伪随机数序列。还是那个例子，这是完全根据心情去选一家店来问了

##### 缺点：

- 这种方法建立起来的hash表当冲突多的时候数据容易堆聚在一起，这时候对查找不友好；
  
- 删除结点不能简单地将被删结 点的空间置为空，否则将截断在它之后填入散列表的同义词结点的查找路径。因此在 用开放地址法处理冲突的散列表上执行删除操作，只能在被删结点上做删除标记，而不能真正删除结点 当空间满了，还要建立一个溢出表来存多出来的元素。

#### 第二种: 再哈希法
Hi = RHi（key），i=1,2,...k
RHi均是不同的哈希函数，即在同义词产生地址冲突时计算另一个哈希函数地址，直到不发生冲突为止。这种方法不易产生聚集，但是增加了计算时间。

##### 缺点: 

- 增加了计算时间

##### 第三种: 建立一个公共溢出区

假设哈希函数的值域为[0,m-1]，则设向量HashTable[0...m-1]为基本表，每个分量存放一个记录，另设立向量OverTable[0....v]为溢出表。所有关键字和基本表中关键字为同义词的记录，不管他们由哈希函数得到的哈希地址是什么，一旦发生冲突，都填入溢出表。

简单地说就是搞个新表存冲突的元素。

#### 第四种: 链地址法（拉链法）

将所有关键字为同义词的记录存储在同一线性链表中，也就是把冲突位置的元素构造成链表。

##### 拉链法的优点:

拉链法处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短； 由于拉链法中各链表上的结点空间是动态申请的，故它更适合于造表前无法确定表长的情况； 在用拉链法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。

##### 拉链法的缺点：

指针需要额外的空间，故当结点规模较小时，开放定址法较为节省空间，而若将节省的指针空间用来扩大散列表的规模，可使装填因子变小，这又减少了开放定址法中的冲突，从而提高平均查找速度

### Java中HashMap的数据结构
HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。
![hashMap数据结构.png](https://i.loli.net/2021/07/19/COjvbLAde3ygUJc.png)

HashMap数据结构，来源于网络,看图就可以知道Java中的hashMap使用了拉链法处理冲突。

- HashMap有一个初始容量大小，默认是16
````
static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16  
````

- 为了减少冲突的概率，当hashMap的数组长度到了一个临界值就会触发扩容，把所有元素rehash再放到扩容后的容器中，这是一个非常耗时的操作。

- 而这个临界值由`加载因子`和`当前容器的容量大小`来确定：
  
**DEFAULT_INITIAL_CAPACITY*DEFAULT_LOAD_FACTOR ，即默认情况下是16x0.75=12时，就会触发扩容操作。**

- 所以使用hash容器时尽量预估自己的数据量来设置初始值。具体代码实现自行去研究HashMap的源码。

----
## 但是为什么一定是0.75？而不是0.8，0.6

- 冲突定义：假设哈希表的地址集为［0，ｎ），冲突是指由关键字得到的哈希地址为j（0<=j<=n-1）的位置上已经有记录。在关键字得到的哈希地址上已经有记录，那么就称之为冲突。

- 处理冲突：就是为该关键字的记录扎到另一个“空”的哈希地址。即在处理哈希地址的冲突时，若得到的另一个哈希地址H1仍然发生冲突，则再求下一个地址H2，若H2仍然冲突，再求的H3，直至Hk不发生冲突为止，则Hk为记录在表中的地址。
#### 基础知识补充完毕，回到正题，为什么加载因子要默认是0.75 从hashmap源码注释里找到了这一段

- 
````
Ideally【理想的】, under random hashCodes, the frequency【频率】 of nodes in bins follows a Poisson【柏松】 distribution【分配】
(http://en.wikipedia.org/wiki/Poisson_distribution) with a
parameter of about 0.5 on average【平均数】 for the default resizing threshold of 0.75, although with a large variance【方差】 because of
resizing【扩容】 granularity【粒度】. Ignoring variance【方差】, the expected【发生】 of list size k are (exp(-0.5) * pow(0.5, k) /
factorial(k)). The first values are:
0: 0.60653066
1: 0.30326533
2: 0.07581633
3: 0.01263606
4: 0.00157952
5: 0.00015795
6: 0.00001316
7: 0.00000094
8: 0.00000006
more: less than 1 in ten million
````

- 在理想的随机hashCode下，容器中节点的频率遵循泊松分布(http://en.wikipedia.org/wiki/Poisson_distribution),
  对于0.75的默认调整阈值，泊松分布的概率质量函数中参数λ（事件发生的平均次数）的值约为0.5，尽管λ的值会因为load factor值的调整而产生较大变化。
  
- load factor的值会影响泊松分布PMF函数公式中的参数λ的值，例如load factor=0.75f时λ=0.5。按照泊松分布公式来看，期望放入bin中数据的数量k=8，e是一个无理常数，λ的值受load factor的值的影响（泊松分布是用来估算在 一段特定时间或空间内发生成功事件的数量的概率，即在长度为length的数组中hash地放入0.75*length数量的数据，数组中某一个下标放入k个数据的概率）。

  
### **关键字：poisson_distribution 泊淞分布**

- `泊松分布`:单位时间内独立事件发生次数的概率分布，`指数分布`:独立事件的时间间隔的概率分布。

- TreeNode虽然改善了链表增删改查的性能，但是其节点大小是链表节点的两倍

- 虽然引入TreeNode但是不会轻易转变为TreeNode（如果存在大量转换那么资源代价比较大），根据**泊松分布**来看转变是小概率事件,性价比是值得的

- 对于HashMap.table[].length的空间来说，放入0.75*length个数据，某一个bin中放入节点数量的概率情况如上图注释中给出的数据（表示数组某一个下标存放数据数量为0~8时的概率情况）

  - 举个例子说明，HashMap默认的table[].length=16，在长度为16的HashMap中放入12（0.75*length）个数据，某一个bin中存放了8个节点的概率是0.00000006
  - 扩容一次，16*2=32，在长度为32的HashMap中放入24个数据，某一个bin中存放了8个节点的概率是0.00000006
  - 再扩容一次，32*2=64，在长度为64的HashMap中放入48个数据，某一个bin中存放了8个节点的概率是0.00000006

所以，当某一个bin的节点大于等于8个的时候，就可以从链表node转换为 **treeNode**，其性价比是值得的。

-  不是因为loadfactor=0.75所以符合泊松分布，而是理想随机哈希的方式满足泊松分布，不管**loadfactor**等于多少，只要是理想随即哈希都满足泊松分布。