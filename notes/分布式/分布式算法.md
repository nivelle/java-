#### CPA理论

#### ACID 理论

通常情况下，我们所说的事务指的都是本地事务，也就是在单机上的事务。而事务具备四大基本特征 ACID，具体含义如下。

- A:原子性（Atomicity），即事务最终的状态只有两种，全部执行成功和全部不执行，不会停留在中间某个环节。若处理事务的任何一项操作不成功，就会导致整个事务失败。一旦操作失败，所有操作都会被取消（即回滚），使得事务仿佛没有被执行过一样。就好比买一件商品，购买成功时，则给商家付了钱，商品到手；购买失败时，则商品在商家手中，消费者的钱也没花出去。
  
- C:一致性（Consistency），是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）。
  
- I:隔离性（Isolation），是指当系统内有多个事务并发执行时，多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。
  
- D:持久性（Durability），也被称为永久性，是指一个事务被执行后，那么它对数据库所做的更新就永久地保存下来了。即使发生系统崩溃或宕机等故障，重新启动数据库系统后，只要数据库能够重新被访问，那么一定能够将其恢复到事务完成时的状态。就像消费者在网站上的购买记录，即使换了手机，也依然可以查到。

#### BASE 理论

分布式存储系统的设计模式——BASE 理论。 BASE 理论包括:

- 基本可用(Basically Available)

基本可用：分布式系统出现故障的时候，允许损失一部分功能的可用性，保证核心功能可用。比如，某些电商 618 大促的时候，会对一些非核心链路的功能进行降级处理。
  
- 柔性状态(Soft State)

在柔性事务中，**允许系统存在中间状态**，且这个中间状态不会影响系统整体可用性。比如，数据库读写分离，写库同步到读库（主库同步到从库）会有一个延时，其实就是一种柔性状态。

- 最终一致性(Eventual Consistency)

事务在操作过程中可能会由于同步延迟等问题导致不一致，但最终状态下，所有数据都是一致的

##### BASE 理论为了支持大型分布式系统，通过牺牲强一致性，保证最终一致性，来获得高可用性，是对 ACID 原则的弱化。

##### ACID 与 BASE 是对一致性和可用性的权衡所产生的不同结果，但二者都保证了数据的持久性。ACID 选择了强一致性而放弃了系统的可用性。与 ACID 原则不同的是，BASE 理论保证了系统的可用性，允许数据在一段时间内可以不一致，最终达到一致状态即可，也即牺牲了部分的数据一致性，选择了最终一致性。


#### 二阶段提交、三阶段提交方法，遵循的是ACID原则，而消息最终一致性方案遵循的是BASE理论

--------

### 分布式事务

分布式事务，就是在分布式系统中运行的事务，由多个本地事务组合而成。在分布式场景下，对事务的处理操作可能来自不同的机器，甚至是来自不同的操作系统。

- 分布式事务由多个事务组成，因此基本满足 ACID，其中的 C 是强一致性，也就是所有操作均执行成功，才提交最终结果，以保证数据一致性或完整性。

- 但随着分布式系统规模不断扩大，复杂度急剧上升，达成强一致性所需时间周期较长，限定了复杂业务的处理。为了适应复杂业务，出现了 BASE 理论，该理论的一个关键点就是采用最终一致性代替强一致性。


----------
### 分布式互斥算法分类

[![6TEssK.md.png](https://z3.ax1x.com/2021/03/22/6TEssK.md.png)](https://imgtu.com/i/6TEssK)

### 分布式选主算法

#### Bully算法

[![6Taa2q.md.png](https://z3.ax1x.com/2021/03/23/6Taa2q.md.png)](https://imgtu.com/i/6Taa2q)

##### 选举过程

1. 集群中每个节点判断自己的 ID 是否为当前活着的节点中 ID 最大的，如果是,则直接向其他节点发送 Victory 消息，宣誓自己的主权；

2. 如果自己不是当前活着的节点中 ID 最大的，则向比自己 ID 大的所有节点发送 Election 消息，并等待其他节点的回复；

3. 若在给定的时间范围内,本节点没有收到其他节点回复的 Alive 消息,则认为自己成为主节点，并向其他节点发送 Victory 消息，宣誓自己成为主节点; 
   
4. 若接收到来自比自己 ID 大的节点的 Alive 消息，则等待其他节点发送 Victory 消息;

5. 若本节点收到比自己 ID 小的节点发送的 Election 消息，则回复一个 Alive 消息，告知其他节点，我比你大，重新选举。

##### bully 应用

- 目前已经有很多开源软件采用了 Bully 算法进行选主比如 MongoDB 的副本集故障转移功能。

````
MongoDB 的分布式选举中，采用节点的最后操作时间戳来表示 ID，时间戳最新的节点其 ID 最大，也就是说时间戳最新的、活着的节点是主节点。

但这种算法的缺点在于，需要每个节点有全局的节点信息，因此额外信息存储较多；

其次，任意一个比当前主节点 ID 大的新节点或节点故障后恢复加入集群的时候，都可能会触发重新选举，成为新的主节点，如果该节点频繁退出、加入集群，就会导致频繁切主。

````

#### Raft 算法

###### Raft 算法,集群节点角色

- Leader:即主节点，同一时刻只有一个 Leader，负责协调和管理其他节点;

- Candidate: 即候选者,每一个节点都可以成为 Candidate,节点在该角色下才可以被选为新的 Leader;

- Follower: Leader 的跟随者，不可以发起选举。

### 选举过程

1. 初始化时，所有节点均为 Follower 状态。

2. 开始选主时，所有节点的状态由 Follower 转化为 Candidate，并向其他节点发送选举请求。

3. 其他节点根据接收到的选举请求的先后顺序，回复是否同意成为主。这里需要注意的是,__在每一轮选举中,一个节点只能投出一张票__。

4. 若发起选举请求的节点获得超过一半的投票，则成为主节点，其状态转化为 Leader,其他节点的状态则由 Candidate 降为 Follower。
   Leader 节点与 Follower 节点之间会定期发送心跳包，以检测主节点是否活着。

5. 当 Leader 节点的任期到了，即发现其他服务器开始下一轮选主周期时，Leader 节点的状态由 Leader 降级为 Follower，进入新一轮选主。

6. Follower 节点与leader失联后，经过随机的超时时间，成为 Follower 节点，然后发起投票；接收节点如果在这一轮中未投过票则投票给 Candidate 节点

7. Follower 节点投完票后重置其超时时间

8. Follower 成为leader后开始接收读写请求，并同步给Follower节点；同步数据是随着心跳检测来发送到Follower的

9. 如果Follower 收不到心跳检测，则成为 Candidate开始重新选举

10. 如果在一个周期内没有选举出leader,则等待超时后下一次选举

### 脑裂问题

1. 部分分区因为无法获取投票中的大多数所以无法提交，也可能有分区可以获取大部分投票

##### raft 应用

- Google 开源的 Kubernetes，擅长容器管理与调度，为了保证可靠性，通常会部署 3 个节点用于数据备份

``````
这 3 个节点中，有一个会被选为主，其他节点作为备。Kubernetes 的选主采用的是开源的 etcd 组件。而 etcd 的集群管理器 etcds,是一个高可用、强一致性的服务发现存储仓库,就是采用了 Raft 算法来实现选主和一致性的。

Raft 算法具有选举速度快、算法复杂度低、易于实现的优点；缺点是，它要求系统内每个节点都可以相互通信，且需要获得过半的投票数才能选主成功，因此通信量大。该算法选举稳定性比 Bully 算法好，这是因为当有新节点加入或节点故障恢复后，会触发选主，但不一定会真正切主，除非新节点或故障后恢复的节点获得投票数过半，才会导致切主。
``````
- Tidb 、CockroachDb


#### ZAB算算法

##### 集群节点角色

- Leader，主节点；

- Follower，跟随者节点；

- Observer，观察者，无投票权。

##### 集群节点状态

- Looking 状态，即选举状态。当节点处于该状态时，它会认为当前集群中没有 Leader，因此自己进入选举状态。

- Leading 状态，即领导者状态，表示已经选出主，且当前节点为 Leader。

- Following 状态，即跟随者状态，集群中已经选出主后，其他非主节点状态更新为 Following，表示对 Leader 的追随。

- Observing 状态，即观察者状态，表示当前节点为 Observer，持观望态度，没有投票权和选举权。

````
投票过程中，每个节点都有一个唯一的三元组 (server_id, server_zxID, epoch)，其中 server_id 表示本节点的唯一 ID；server_zxID 表示本节点存放的数据 ID，数据 ID 越大表示数据越新，选举权重越大；epoch 表示当前选取轮数，一般用逻辑时钟表示。


ZAB 选举算法的核心是“少数服从多数，ID 大的节点优先成为主”，因此选举过程中通过 (vote_id, vote_zxID) 来表明投票给哪个节点，其中 vote_id 表示被投票节点的 ID，vote_zxID 表示被投票节点的服务器 zxID。

````

**ZAB 算法选主的原则是：server_zxID 最大者成为 Leader；若 server_zxID 相同，则 server_id 最大者成为 Leader**

##### 选举过程

- 第一步：当系统刚启动时，3 个服务器当前投票均为第一轮投票，即 epoch=1，且 zxID 均为 0。此时每个服务器都推选自己，并将选票信息 <epoch, vote_id, vote_zxID> 广播出去。

- 第二步：根据判断规则，由于 3 个 Server 的 epoch、zxID 都相同，因此比较 server_id，较大者即为推选对象，因此 Server 1 和 Server 2 将 vote_id 改为 3，更新自己的投票箱并重新广播自己的投票。

- 第三步：此时系统内所有服务器都推选了 Server 3，因此 Server 3 当选 Leader，处于 Leading 状态，向其他服务器发送心跳包并维护连接；Server1 和 Server2 处于 Following 状态。

[![6T6UJS.jpg](https://z3.ax1x.com/2021/03/23/6T6UJS.jpg)](https://imgtu.com/i/6T6UJS)

### Paxos算法

基于消息传递且具有高度容错性的一致性算法，是目前公认的解决分布式一致问题最有效的算法之一。

#### 问题描述

假设有一组可以提出提案的进程集合，那么对于一个一致性算法来说需要保证以下几点：

- 在这些被提出的提案中，只有一个会被选定。
- 如果没有提案被提出，那么就不会有被选定的提案。
- 当一个提案被选定后，进程应该可以获取被选定的提案信息。

对于一致性来说，安全性需求如下：

- 只有被提出的提案才能被选定。
- 只能有个一个值被选定
- 如果某个进程认为某个提案被选定了，那么这个提案必须是真的被选定的那个。

在一致性算法中，有三种参与角色，我么用Proposer(建议人)、Acceptor(接受者)和Learner(学习者)来表示。

提案选取过程：

Proposer向一个Acceptor集合发送提案，同样，集合中的每个Acceptor都可能会批准(Accept)
该提案，当有足够多的Acceptor批准这个提案的时候，我们就可以认为该提案被选定了。我们假定足够多的Acceptor是整个Acceptor集合的一个子集，并且让这个集合大得可以包含Acceptor集合中的大多数成员，因为任意两个包含大多数Acceptor的子集至少有一个公共成员。

##### 推导过程

在没有失败和消息丢失的情况下，如果我们希望即使在只有一个提案被提出的情况下，任然可以选出一个提案，这就暗示了如下的需求。

```
P1:一个Acceptor必须批准它收到的第一个提案。

```

但是：如果有多个提案被不同的Proposer同时提出，这可能会导致虽然每个Acceptor都批准了它收到的第一个提案，但是没有一个提案是由多数人都批准的。另外，即使只有两个提案被提出，如果每个提案都被差不多一半的Acceptor批准了，此时即使只有一个Acceptor出错，都有可能导致无法确定该选定那个提案。

![image](http://7xpuj1.com1.z0.glb.clouddn.com/%E4%B8%8D%E5%90%8C%E7%9A%84Proposer%E5%88%86%E5%88%AB%E6%8F%90%E5%87%BA%E5%A4%9A%E4%B8%AA%E6%8F%90%E6%A1%88.png)

**解决方案：** 我们使用一个全局的编号(这种全局唯一编号的生成并不是Paxos算法需要关注的地方，就算法本身而言，其假设当前已经具备这样的外部组件能够生成一个全局唯一的编号)
来唯一标识每一个被Acceptor批准的提案，当一个具有某Value值得提案被半数以上的Acceptor批准后，我们就认为该Value被选定了，此时我们也认为该提案被选定了。需要注意的是，此处讲到的提案已经和Value不是同一个概念了，提案变成了一个由编号和Value组成的组合体，因此我们以“[编号，Value]
”来表示一个提案。

根据上面讲到的内容，我们虽然允许多个提案被选定，但同时必须要保证所有被选定的提案都具有相同的Value值————这是一个关于提案Value的约定，结合提案的编号，该约定可以定义如下：

```
P2 :如果编号为M0、Value值为V0的提案(即[M0，V0])被选定了，那么所有比编号M0更高的，且被选定的提案，其Value值必须也是V0 .

```

因为提案的编号是全序的，条件P2就保证了只有一个Value值被选定这一个关键安全性属性。同时，一个提案要被选定，其首先必须被至少一个Acceptor批准，因此我们可以通过满足如下条件来满足P2.

```
p2a:如果编号为M0、value值为V0的提案(即[M0，V0])被选定了，
那么所有比编号M0更高的，且被Acceptor批准的提案，其Value值必须也是V0.

```

因为通信是异步的，一个提案可能会在某个Acceptor还未收到任何提案时就被选定了：

```
P2b:如果一个提案[M0，V0]被选定后，那么之后任何Proposer产生的编号更高的提案，其Value值都为V0.

```

因为一个提案必须在被Proposer提出后才能被Acceptor批准，因此P2b包含了P2a，进而包含了P2。于是，接下去的重点就是论证P2b成立即可：

```
假设某个提案[M0，V0]已经被选定了，证明任何编号Mn>M0的天，其值都是V0.
```

#### Proposer生成提案

- Proposer选择一个新的提案编号Mn，然后向某个Acceptor集合的成员发送请求，要求改集合中的Acceptor做出如下回应。

1. 向Proposer承诺，保证不再批准任何编号小于Mn的提案

2. 如果Acceptor已经批准过任何提案，那么其向Proposer反馈当前Acceptor已经批准的标号小于Mn但为最大编号的的那个提案的值。

-
如果Proposer收到了来自半数以上的Acceptor的相应结果，那么它就可以产生编号为Mn,Value值为Vn的提案，这里的Vn是所有响应编号中最大的提案的Value值。当然还存在另一种情况，就是半数以上的Acceptor都没有批准过任何提案，即响应中不包含任何的提案，那么此时Vn值就可以有Proposer任意选择。

#### Acceptor批准提案

在上文，我们已经讲解了Paxos算法中Proposer的处理逻辑，根据上面的内容，一个Acceptor可能会收到来自Proposer的两种请求，分别是Prepare请求和Acceptor请求，对着两类请求做出响应的条件分别如下。

- Prepare请求：Acceptor可以在任何时候响应一个Prepare请求。
- Accept请求：在不违背Accept现有承诺前提表，可以任意响应Accept请求。

因此，对于Acceptor逻辑处理的约束条件，大体可以定义如下。

```
P1a:一个Acceptor只要尚未响应过任何编号大于Mn的Prepare请求，那么就可以接受这个编号为Mn的提案。
```

